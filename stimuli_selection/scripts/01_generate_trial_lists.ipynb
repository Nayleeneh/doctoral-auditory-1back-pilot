{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Outputs (overwritten on each run):**\n",
        "- `experiment/resources/lists/con_run1.csv`\n",
        "- `experiment/resources/lists/abs_run1.csv`\n",
        "- `experiment/resources/lists/con_run2.csv`\n",
        "- `experiment/resources/lists/abs_run2.csv`\n",
        "\n",
        "**Outputs overwritten by 04_generate_baseline_files.ipynb:**\n",
        "- `experiment/resources/lists/base_run1.csv`\n",
        "- `experiment/resources/lists/base_run2.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c60154e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "from __future__ import annotations\n",
        "import re\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import ks_2samp, levene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# config\n",
        "\n",
        "CSV_ENCODING = \"utf-8-sig\"\n",
        "\n",
        "RNG_SEED = 42\n",
        "rng = np.random.default_rng(RNG_SEED)\n",
        "\n",
        "THIS_DIR = Path.cwd()\n",
        "ROOT = THIS_DIR.parents[1]          \n",
        "STIMSEL = ROOT / \"stimuli_selection\"\n",
        "LEX = STIMSEL / \"lexicons\"\n",
        "\n",
        "SUBTLEX_PATH = LEX / \"subtlex-pl.csv\"\n",
        "ANPW_PATH    = LEX / \"anpw_r.csv\"\n",
        "\n",
        "OUT_LISTS = ROOT / \"experiment\" / \"resources\" / \"lists\"\n",
        "OUT_LISTS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# global blacklist\n",
        "\n",
        "BLACKLIST = {\n",
        "    \"północ\", \"czar\", \"moment\", \"słowo\", \"śmierć\", \"wrogi\", \"LOL\",\n",
        "    \"demon\", \"masakra\", \"typ\", \"rok\", \"ciasteczko\", \"turbo\", \"szał\",\n",
        "    \"tyłek\", \"korek\", \"kolor\", \"brak\", \"data\", \"głupiec\", \"frajer\",\n",
        "    \"słodycze\", \"układność\", \"faza\", \"pakt\", \"budynek\", \"brawo\",\n",
        "    \"sezon\", \"rodzaj\", \"mistrz\", \"wartość\", \"smoking\", \"Budda\",\n",
        "    \"orgazm\", \"Graal\", \"flaki\", \"szaleniec\", \"istota\", \"drań\", \"Wigilia\",\n",
        "    \"szok\", \"racja\", \"wiedza\", \"gniew\", \"sprzeciw\", \"tchórz\", \"chwała\",\n",
        "    \"guru\", \"podbródek\", \"skóra\", \"stodoła\", \"szczur\", \"pies\", \"żaba\",\n",
        "    \"władza\", \"wstyd\", \"ból\", \"wola\", \"macho\", \"geniusz\", \"wóz\", \"szyja\",\n",
        "    \"pióro\", \"ryba\", \"radio\", \"ser\", \"styl\", \"suma\", \"trud\", \"standard\",\n",
        "    \"równie\", \"zupa\", \"bank\", \"sposób\", \"głupota\", \"śmiech\", \"plus\", \"norma\",\n",
        "    \"pech\", \"szczerość\", \"stan\", \"ego\", \"solo\", \"los\", \"stół\", \"blok\", \"strata\",\n",
        "    \"spór\", \"sprawa\", \"wpadka\", \"czapka\", \"dziób\", \"kask\", \"jeep\", \"miód\",\n",
        "    \"gamma\", \"hańba\", \"kwiat\", \"Frisbee\", \"spojrzenie\", \"plan\", \"skala\",\n",
        "    \"dzbanek\", \"drzewo\", \"ziemniaki\", \"sok\", \"nuda\", \"plugawstwo\", \"malarstwo\",\n",
        "    \"lód\", \"chleb\"\n",
        "\n",
        "}\n",
        "\n",
        "BLACKLIST = {w.strip().lower() for w in BLACKLIST if isinstance(w, str) and w.strip()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24, 24, 48, 48, 24)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# design\n",
        "\n",
        "N_TRIALS_PER_BLOCK = 8\n",
        "N_CON_BLOCKS_PER_RUN = 3\n",
        "N_ABS_BLOCKS_PER_RUN = 3\n",
        "N_BASE_BLOCKS_PER_RUN = 6\n",
        "N_RUNS = 2\n",
        "\n",
        "N_CON_PER_RUN = N_TRIALS_PER_BLOCK * N_CON_BLOCKS_PER_RUN\n",
        "N_ABS_PER_RUN = N_TRIALS_PER_BLOCK * N_ABS_BLOCKS_PER_RUN\n",
        "N_BASE_PER_RUN = N_CON_PER_RUN\n",
        "\n",
        "N_CON_TOTAL = N_CON_PER_RUN * N_RUNS\n",
        "N_ABS_TOTAL = N_ABS_PER_RUN * N_RUNS\n",
        "\n",
        "N_CON_PER_RUN, N_ABS_PER_RUN, N_CON_TOTAL, N_ABS_TOTAL, N_BASE_PER_RUN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_subtlex_auto(path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path, sep=None, engine=\"python\", encoding=\"utf-8\")\n",
        "    df = df.rename(columns={\"spelling\": \"word\", \"zipf.freq\": \"zipf\"})\n",
        "    if \"word\" not in df.columns:\n",
        "        raise ValueError(\"SUBTLEX: missing 'spelling' column.\")\n",
        "    if \"zipf\" not in df.columns:\n",
        "        raise ValueError(\"SUBTLEX: missing 'zipf.freq' column.\")\n",
        "    if \"nchar\" not in df.columns:\n",
        "        df[\"nchar\"] = df[\"word\"].astype(str).str.len()\n",
        "    df[\"word\"] = df[\"word\"].astype(str).str.strip()\n",
        "    df[\"zipf\"] = pd.to_numeric(df[\"zipf\"], errors=\"coerce\")\n",
        "    df[\"nchar\"] = pd.to_numeric(df[\"nchar\"], errors=\"coerce\")\n",
        "    return df[[\"word\", \"zipf\", \"nchar\"]].drop_duplicates(\"word\")\n",
        "\n",
        "def read_anpw(path: Path) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path, sep=\";\", encoding=\"utf-8\", engine=\"python\")\n",
        "    if \"polish word\" in df.columns:\n",
        "        df = df.rename(columns={\"polish word\": \"word\"})\n",
        "    if \"part of speach\" in df.columns:\n",
        "        df = df.rename(columns={\"part of speach\": \"pos\"})\n",
        "    df[\"word\"] = df[\"word\"].astype(str).str.strip()\n",
        "\n",
        "    num_cols = [\n",
        "        \"Number of Letters\",\n",
        "        \"concretness_M\",\n",
        "        \"imegability_M\",\n",
        "        \"Valence_M\",\n",
        "        \"arousal_M\",\n",
        "        \"subtlex_pl frequency\",\n",
        "    ]\n",
        "    for c in num_cols:\n",
        "        if c in df.columns:\n",
        "            df[c] = (\n",
        "                df[c].astype(str)\n",
        "                    .str.replace(\",\", \".\", regex=False)\n",
        "                    .replace({\"nan\": np.nan, \"\": np.nan})\n",
        "            )\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "    if \"Number of Letters\" in df.columns:\n",
        "        df[\"nchar\"] = df[\"Number of Letters\"]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a9edf143",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>word</th>\n",
              "      <th>english word</th>\n",
              "      <th>subtlex_pl frequency</th>\n",
              "      <th>Kazojć (2011) frequency</th>\n",
              "      <th>pos</th>\n",
              "      <th>Number of Letters</th>\n",
              "      <th>Valence_N</th>\n",
              "      <th>Valence_MIN</th>\n",
              "      <th>Valence_MAX</th>\n",
              "      <th>...</th>\n",
              "      <th>imegability_M_Male</th>\n",
              "      <th>imegability_SD_Male</th>\n",
              "      <th>ageOfAquisition_N_Male</th>\n",
              "      <th>ageOfAquisition_MIN_Male</th>\n",
              "      <th>ageOfAquisition_MAX_Male</th>\n",
              "      <th>ageOfAquisition_M_Male</th>\n",
              "      <th>ageOfAquisition_SD_Male</th>\n",
              "      <th>nchar</th>\n",
              "      <th>zipf</th>\n",
              "      <th>nchar_subtlex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>131</td>\n",
              "      <td>belka</td>\n",
              "      <td>beam</td>\n",
              "      <td>72</td>\n",
              "      <td>332</td>\n",
              "      <td>N</td>\n",
              "      <td>5.0</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>7,48</td>\n",
              "      <td>1,782320585</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>7,88</td>\n",
              "      <td>3,059411708</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.696093</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>173</td>\n",
              "      <td>bęben</td>\n",
              "      <td>drum</td>\n",
              "      <td>228</td>\n",
              "      <td>522</td>\n",
              "      <td>N</td>\n",
              "      <td>5.0</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>7,84</td>\n",
              "      <td>1,885912688</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>7,64</td>\n",
              "      <td>2,360790828</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.192606</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>220</td>\n",
              "      <td>boa</td>\n",
              "      <td>boa</td>\n",
              "      <td>170</td>\n",
              "      <td>139</td>\n",
              "      <td>ign</td>\n",
              "      <td>3.0</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>7,64</td>\n",
              "      <td>1,8</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>10,24</td>\n",
              "      <td>3,950527391</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.065766</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1177</td>\n",
              "      <td>ketchup</td>\n",
              "      <td>ketchup</td>\n",
              "      <td>281</td>\n",
              "      <td>18</td>\n",
              "      <td>N</td>\n",
              "      <td>7.0</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>7,6</td>\n",
              "      <td>1,94</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>7,2</td>\n",
              "      <td>2,42</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.283019</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1394</td>\n",
              "      <td>królik</td>\n",
              "      <td>bunny / rabbit</td>\n",
              "      <td>1084</td>\n",
              "      <td>528</td>\n",
              "      <td>N</td>\n",
              "      <td>6.0</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>8,16</td>\n",
              "      <td>1,62</td>\n",
              "      <td>25</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>2,33</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.868200</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 130 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     word    english word  subtlex_pl frequency  \\\n",
              "0         131    belka            beam                    72   \n",
              "1         173    bęben            drum                   228   \n",
              "2         220      boa             boa                   170   \n",
              "3        1177  ketchup         ketchup                   281   \n",
              "4        1394   królik  bunny / rabbit                  1084   \n",
              "\n",
              "  Kazojć (2011) frequency  pos  Number of Letters  Valence_N  Valence_MIN  \\\n",
              "0                     332    N                5.0         50            2   \n",
              "1                     522    N                5.0         50            3   \n",
              "2                     139  ign                3.0         49            1   \n",
              "3                      18    N                7.0         50            3   \n",
              "4                     528    N                6.0         50            3   \n",
              "\n",
              "   Valence_MAX  ...  imegability_M_Male imegability_SD_Male  \\\n",
              "0            8  ...                7,48         1,782320585   \n",
              "1            8  ...                7,84         1,885912688   \n",
              "2            8  ...                7,64                 1,8   \n",
              "3            9  ...                 7,6                1,94   \n",
              "4            8  ...                8,16                1,62   \n",
              "\n",
              "   ageOfAquisition_N_Male  ageOfAquisition_MIN_Male  ageOfAquisition_MAX_Male  \\\n",
              "0                      25                         3                        14   \n",
              "1                      25                         4                        12   \n",
              "2                      25                         5                        18   \n",
              "3                      25                         4                        12   \n",
              "4                      25                         3                        12   \n",
              "\n",
              "   ageOfAquisition_M_Male ageOfAquisition_SD_Male  nchar      zipf  \\\n",
              "0                    7,88             3,059411708    5.0  2.696093   \n",
              "1                    7,64             2,360790828    5.0  3.192606   \n",
              "2                   10,24             3,950527391    3.0  3.065766   \n",
              "3                     7,2                    2,42    7.0  3.283019   \n",
              "4                       6                    2,33    6.0  3.868200   \n",
              "\n",
              "   nchar_subtlex  \n",
              "0            5.0  \n",
              "1            5.0  \n",
              "2            3.0  \n",
              "3            7.0  \n",
              "4            6.0  \n",
              "\n",
              "[5 rows x 130 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subtlex = read_subtlex_auto(SUBTLEX_PATH)\n",
        "anpw = read_anpw(ANPW_PATH)\n",
        "\n",
        "df = anpw.merge(subtlex, on=\"word\", how=\"left\", suffixes=(\"\", \"_subtlex\"))\n",
        "df[\"nchar\"] = df[\"nchar\"].fillna(df.get(\"nchar_subtlex\")).fillna(df[\"word\"].str.len())\n",
        "df[\"nchar\"] = pd.to_numeric(df[\"nchar\"], errors=\"coerce\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "VOWELS = set(\"aąeęioóuy\")\n",
        "\n",
        "def count_syllables_pl(word: str) -> int:\n",
        "    w = word.lower()\n",
        "    groups = 0\n",
        "    in_vowel = False\n",
        "    for ch in w:\n",
        "        is_v = ch in VOWELS\n",
        "        if is_v and not in_vowel:\n",
        "            groups += 1\n",
        "        in_vowel = is_v\n",
        "    return max(groups, 1)\n",
        "\n",
        "df[\"syllables\"] = df[\"word\"].map(count_syllables_pl)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2500, 132)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def is_simple_word(w: str) -> bool:\n",
        "    return bool(re.fullmatch(r\"[A-Za-zĄĆĘŁŃÓŚŹŻąćęłńóśźż]+\", w))\n",
        "\n",
        "df_f = df.copy()\n",
        "\n",
        "# Apply blacklist early (before any quantiles/sampling)\n",
        "df_f[\"word_norm\"] = df_f[\"word\"].astype(str).str.strip().str.lower()\n",
        "df_f = df_f[~df_f[\"word_norm\"].isin(BLACKLIST)].copy()\n",
        "\n",
        "if \"pos\" in df_f.columns:\n",
        "    df_f = df_f[df_f[\"pos\"].astype(str).str.upper().eq(\"N\")]\n",
        "\n",
        "df_f = df_f[df_f[\"word\"].map(is_simple_word)]\n",
        "df_f = df_f[df_f[\"concretness_M\"].notna()]\n",
        "df_f = df_f[df_f[\"nchar\"].between(3, 10)]\n",
        "df_f = df_f.drop_duplicates(subset=[\"word\"]).reset_index(drop=True)\n",
        "\n",
        "df_f.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(np.float64(2.04), np.float64(4.24), (630, 132), (637, 132))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q_low, q_high = 0.25, 0.75\n",
        "low_thr = df_f[\"concretness_M\"].quantile(q_low)\n",
        "high_thr = df_f[\"concretness_M\"].quantile(q_high)\n",
        "\n",
        "# ANPW_R: lower concreteness_M = more concrete; higher = more abstract\n",
        "\n",
        "con_pool = df_f[df_f[\"concretness_M\"] <= low_thr].copy().reset_index(drop=True)\n",
        "abs_pool = df_f[df_f[\"concretness_M\"] >= high_thr].copy().reset_index(drop=True)\n",
        "\n",
        "low_thr, high_thr, abs_pool.shape, con_pool.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((380, 134), (381, 134))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# stronger preference for common words, but only within the extreme concreteness\n",
        "W_CONC = 2.0    # concreteness primary\n",
        "W_ZIPF = 1.2    # frequency preference\n",
        "ZIPF_MIN = 3.0  # hard floor\n",
        "\n",
        "def z(x: pd.Series) -> pd.Series:\n",
        "    return (x - x.mean()) / (x.std(ddof=0) + 1e-8)\n",
        "\n",
        "def rank_pool(pool: pd.DataFrame, cond: str) -> pd.DataFrame:\n",
        "    p = pool.copy()\n",
        "    p[\"zipf_filled\"] = p[\"zipf\"].fillna(p[\"zipf\"].median())\n",
        "    if ZIPF_MIN is not None:\n",
        "        p = p[p[\"zipf_filled\"] >= ZIPF_MIN].copy()\n",
        "\n",
        "    # CON: low concretness_M\n",
        "    # ABS: very high concretness_M\n",
        "    extremeness = (-p[\"concretness_M\"]) if cond == \"CON\" else p[\"concretness_M\"]\n",
        "    p[\"score\"] = W_CONC * z(extremeness) + W_ZIPF * z(p[\"zipf_filled\"])\n",
        "    return p.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "abs_ranked = rank_pool(abs_pool, \"ABS\")\n",
        "con_ranked = rank_pool(con_pool, \"CON\")\n",
        "\n",
        "K_MULT = 8\n",
        "K_abs = min(len(abs_ranked), max(N_ABS_TOTAL * K_MULT, N_ABS_TOTAL))\n",
        "K_con = min(len(con_ranked), max(N_CON_TOTAL * K_MULT, N_CON_TOTAL))\n",
        "\n",
        "abs_pool2 = abs_ranked.iloc[:K_abs].copy().reset_index(drop=True)\n",
        "con_pool2 = con_ranked.iloc[:K_con].copy().reset_index(drop=True)\n",
        "\n",
        "abs_pool2.shape, con_pool2.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\kinga\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:579: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
            "  res = hypotest_fun_out(*samples, **kwds)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'score': -7.791430701211294,\n",
              " 'mismatch_penalty': 0.13604527263502922,\n",
              " 'mean_zipf_total': 7.927475973846324}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FEATURES = [\"nchar\", \"syllables\", \"zipf_filled\"]\n",
        "\n",
        "def prep_features(df_in: pd.DataFrame) -> pd.DataFrame:\n",
        "    d = df_in.copy()\n",
        "    d[\"zipf_filled\"] = d[\"zipf\"].fillna(d[\"zipf\"].median())\n",
        "    return d\n",
        "\n",
        "abs_pool2 = prep_features(abs_pool2)\n",
        "con_pool2 = prep_features(con_pool2)\n",
        "\n",
        "def greedy_match(abs_df: pd.DataFrame, con_df: pd.DataFrame, n_pairs: int, seed: int):\n",
        "    rng_local = np.random.default_rng(seed)\n",
        "\n",
        "    abs_feat = np.column_stack([abs_df[f].to_numpy() for f in FEATURES])\n",
        "    con_feat = np.column_stack([con_df[f].to_numpy() for f in FEATURES])\n",
        "\n",
        "    all_feat = np.vstack([abs_feat, con_feat])\n",
        "    mu = all_feat.mean(axis=0)\n",
        "    sd = all_feat.std(axis=0) + 1e-8\n",
        "\n",
        "    abs_z = (abs_feat - mu) / sd\n",
        "    con_z = (con_feat - mu) / sd\n",
        "\n",
        "    order = rng_local.permutation(len(abs_df))\n",
        "\n",
        "    chosen_abs = []\n",
        "    chosen_con = []\n",
        "    available_con = set(range(len(con_df)))\n",
        "\n",
        "    for i in order:\n",
        "        if len(chosen_abs) >= n_pairs or not available_con:\n",
        "            break\n",
        "        con_list = np.array(sorted(list(available_con)))\n",
        "        dists = np.linalg.norm(con_z[con_list] - abs_z[i], axis=1)\n",
        "        j = con_list[int(np.argmin(dists))]\n",
        "        chosen_abs.append(i)\n",
        "        chosen_con.append(j)\n",
        "        available_con.remove(j)\n",
        "\n",
        "    return abs_df.iloc[chosen_abs].copy(), con_df.iloc[chosen_con].copy()\n",
        "\n",
        "def mismatch_penalty(abs_sel: pd.DataFrame, con_sel: pd.DataFrame) -> float:\n",
        "    ks_ps = []\n",
        "    var_ps = []\n",
        "    for f in FEATURES:\n",
        "        ks_ps.append(ks_2samp(abs_sel[f], con_sel[f]).pvalue)\n",
        "        var_ps.append(levene(abs_sel[f], con_sel[f], center=\"median\").pvalue)\n",
        "    eps = 1e-12\n",
        "    return float(-np.sum(np.log(np.clip(ks_ps, eps, 1.0))) - np.sum(np.log(np.clip(var_ps, eps, 1.0))))\n",
        "\n",
        "def score_total(abs_sel: pd.DataFrame, con_sel: pd.DataFrame) -> float:\n",
        "    pen = mismatch_penalty(abs_sel, con_sel)\n",
        "    mean_zipf = float(abs_sel[\"zipf_filled\"].mean() + con_sel[\"zipf_filled\"].mean())\n",
        "    FREQ_REWARD_WEIGHT = 1.0\n",
        "    return pen - FREQ_REWARD_WEIGHT * mean_zipf\n",
        "\n",
        "def search_best(abs_df: pd.DataFrame, con_df: pd.DataFrame, n_pairs: int, n_tries: int = 800):\n",
        "    best_score = None\n",
        "    best_abs = None\n",
        "    best_con = None\n",
        "    meta = None\n",
        "    for _ in range(n_tries):\n",
        "        seed = int(rng.integers(0, 1_000_000))\n",
        "        a_sel, c_sel = greedy_match(abs_df, con_df, n_pairs=n_pairs, seed=seed)\n",
        "        if len(a_sel) < n_pairs or len(c_sel) < n_pairs:\n",
        "            continue\n",
        "        s = score_total(a_sel, c_sel)\n",
        "        if best_score is None or s < best_score:\n",
        "            best_score = s\n",
        "            best_abs, best_con = a_sel, c_sel\n",
        "            meta = {\n",
        "                \"score\": float(s),\n",
        "                \"mismatch_penalty\": mismatch_penalty(a_sel, c_sel),\n",
        "                \"mean_zipf_total\": float(a_sel[\"zipf_filled\"].mean() + c_sel[\"zipf_filled\"].mean()),\n",
        "            }\n",
        "    if best_abs is None:\n",
        "        raise RuntimeError(\"No solution found — relax ZIPF_MIN/K_MULT/filters.\")\n",
        "    return best_abs, best_con, meta\n",
        "\n",
        "n_pairs = min(N_ABS_TOTAL, len(abs_pool2), len(con_pool2))\n",
        "abs_sel_all, con_sel_all, meta = search_best(abs_pool2, con_pool2, n_pairs=n_pairs, n_tries=800)\n",
        "meta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((24, 134), (24, 134), (24, 134), (24, 134))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# split to runs\n",
        "\n",
        "n_needed = min(N_ABS_TOTAL, len(abs_sel_all), len(con_sel_all))\n",
        "\n",
        "perm = rng.permutation(len(abs_sel_all))\n",
        "abs_sel_all = abs_sel_all.iloc[perm].reset_index(drop=True).iloc[:n_needed]\n",
        "con_sel_all = con_sel_all.iloc[perm].reset_index(drop=True).iloc[:n_needed]\n",
        "\n",
        "abs_run1 = abs_sel_all.iloc[:N_ABS_PER_RUN].copy()\n",
        "abs_run2 = abs_sel_all.iloc[N_ABS_PER_RUN:N_ABS_PER_RUN*2].copy()\n",
        "\n",
        "con_run1 = con_sel_all.iloc[:N_CON_PER_RUN].copy()\n",
        "con_run2 = con_sel_all.iloc[N_CON_PER_RUN:N_CON_PER_RUN*2].copy()\n",
        "\n",
        "abs_run1.shape, abs_run2.shape, con_run1.shape, con_run2.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "WindowsPath('c:/Users/kinga/Documents/Blindbrain/4. Courses/fMRI - design of the experiment and data analysis/cognes-auditory-1back-pilot/experiment/resources/lists')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def make_list(df_in: pd.DataFrame, cond: str, run: int) -> pd.DataFrame:\n",
        "    return pd.DataFrame({\n",
        "        \"word\": df_in[\"word\"].astype(str),\n",
        "        \"condition\": cond,\n",
        "        \"run\": run,\n",
        "        \"stimFile\": [f\"resources/audio/{cond.lower()}_run{run}_{i+1:03d}.wav\" for i in range(len(df_in))],\n",
        "    })\n",
        "\n",
        "con1 = make_list(con_run1, \"CON\", 1)\n",
        "abs1 = make_list(abs_run1, \"ABS\", 1)\n",
        "con2 = make_list(con_run2, \"CON\", 2)\n",
        "abs2 = make_list(abs_run2, \"ABS\", 2)\n",
        "\n",
        "base1 = pd.DataFrame({\n",
        "    \"word\": [\"<BASELINE>\"] * N_BASE_PER_RUN,\n",
        "    \"condition\": [\"BASE\"] * N_BASE_PER_RUN,\n",
        "    \"run\": [1] * N_BASE_PER_RUN,\n",
        "    \"stimFile\": [\"resources/audio/base_run1.wav\"] * N_BASE_PER_RUN,\n",
        "})\n",
        "base2 = pd.DataFrame({\n",
        "    \"word\": [\"<BASELINE>\"] * N_BASE_PER_RUN,\n",
        "    \"condition\": [\"BASE\"] * N_BASE_PER_RUN,\n",
        "    \"run\": [2] * N_BASE_PER_RUN,\n",
        "    \"stimFile\": [\"resources/audio/base_run2.wav\"] * N_BASE_PER_RUN,\n",
        "})\n",
        "\n",
        "con1.to_csv(OUT_LISTS / \"con_run1.csv\", index=False, encoding=CSV_ENCODING)\n",
        "abs1.to_csv(OUT_LISTS / \"abs_run1.csv\", index=False, encoding=CSV_ENCODING)\n",
        "base1.to_csv(OUT_LISTS / \"base_run1.csv\", index=False, encoding=CSV_ENCODING)\n",
        "\n",
        "con2.to_csv(OUT_LISTS / \"con_run2.csv\", index=False, encoding=CSV_ENCODING)\n",
        "abs2.to_csv(OUT_LISTS / \"abs_run2.csv\", index=False, encoding=CSV_ENCODING)\n",
        "base2.to_csv(OUT_LISTS / \"base_run2.csv\", index=False, encoding=CSV_ENCODING)\n",
        "\n",
        "OUT_LISTS\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
