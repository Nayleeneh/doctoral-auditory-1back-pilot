{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generates **baseline noise audio** and overwrites:\n",
        "- `experiment/resources/lists/base_run1.csv`\n",
        "- `experiment/resources/lists/base_run2.csv`\n",
        "- `experiment/resources/audio/base_run1_*.wav`\n",
        "- `experiment/resources/audio/base_run2_*.wav`\n",
        "\n",
        "**Inputs:**\n",
        "- `experiment/resources/lists/con_run1.csv`, `abs_run1.csv`, `con_run2.csv`, `abs_run2.csv`\n",
        "- corresponding audio files referenced in `stimFile`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "\n",
        "try:\n",
        "    import soundfile as sf\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        \"Missing dependency: soundfile. Install in your env: pip install soundfile\"\n",
        "    ) from e\n",
        "\n",
        "from scipy.signal import butter, filtfilt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(WindowsPath('C:/Users/kinga/Documents/Blindbrain/4. Courses/fMRI - design of the experiment and data analysis/cognes-auditory-1back-pilot/experiment/resources/lists'),\n",
              " WindowsPath('C:/Users/kinga/Documents/Blindbrain/4. Courses/fMRI - design of the experiment and data analysis/cognes-auditory-1back-pilot/experiment/resources/audio'))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# paths\n",
        "\n",
        "THIS_DIR = Path.cwd().resolve()\n",
        "ROOT = THIS_DIR.parents[1]  \n",
        "\n",
        "LISTS_DIR = ROOT / \"experiment\" / \"resources\" / \"lists\"\n",
        "AUDIO_DIR = ROOT / \"experiment\" / \"resources\" / \"audio\"\n",
        "AUDIO_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "LISTS_DIR, AUDIO_DIR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(48000, 220.0, 120.0)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# config\n",
        "\n",
        "CSV_ENCODING = \"utf-8-sig\"\n",
        "RNG_SEED = 12345\n",
        "rng = np.random.default_rng(RNG_SEED)\n",
        "\n",
        "SR_TARGET = 48000 # fixed sampling rate across outputs\n",
        "\n",
        "SMOOTH_HZ = 220.0 # spectral smoothing: larger -> less speech-like detail\n",
        "\n",
        "HP_HZ = 120.0 # mild high-pass to remove \"horror\" low end\n",
        "\n",
        "SSN_SMOOTH_HZ = 260.0   \n",
        "SSN_HP_HZ = 320.0       \n",
        "SSN_LP_HZ = 5200.0      \n",
        "SSN_BP_HZ = (320.0, 5200.0)  \n",
        "\n",
        "N_BASE_PER_RUN: int | None = None\n",
        "\n",
        "SR_TARGET, SMOOTH_HZ, HP_HZ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# audio helpers\n",
        "\n",
        "def read_wav(path: Path) -> tuple[np.ndarray, int]:\n",
        "    x, sr = sf.read(path, dtype=\"float32\")\n",
        "    if x.ndim > 1:\n",
        "        x = x.mean(axis=1)\n",
        "    return x.astype(np.float32), int(sr)\n",
        "\n",
        "def write_wav(path: Path, x: np.ndarray, sr: int) -> None:\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    x = np.asarray(x, dtype=np.float32)\n",
        "    sf.write(path, x, sr, subtype=\"PCM_16\")\n",
        "\n",
        "def resample_if_needed(x: np.ndarray, sr: int, target_sr: int) -> tuple[np.ndarray, int]:\n",
        "    if sr == target_sr:\n",
        "        return x, sr\n",
        "    y = librosa.resample(x, orig_sr=sr, target_sr=target_sr)\n",
        "    return y.astype(np.float32), target_sr\n",
        "\n",
        "def pad_or_trim(x: np.ndarray, target_len: int) -> np.ndarray:\n",
        "    x = np.asarray(x, dtype=np.float32)\n",
        "    if len(x) == target_len:\n",
        "        return x\n",
        "    if len(x) > target_len:\n",
        "        return x[:target_len]\n",
        "    pad = np.zeros(target_len - len(x), dtype=np.float32)\n",
        "    return np.concatenate([x, pad])\n",
        "\n",
        "def rms(x: np.ndarray) -> float:\n",
        "    x = np.asarray(x, dtype=np.float32)\n",
        "    return float(np.sqrt(np.mean(x * x) + 1e-12))\n",
        "\n",
        "def match_rms(y: np.ndarray, target_rms: float) -> np.ndarray:\n",
        "    y_rms = rms(y)\n",
        "    if y_rms <= 0:\n",
        "        return y\n",
        "    return (y * (target_rms / y_rms)).astype(np.float32)\n",
        "\n",
        "def hard_clip(x: np.ndarray, limit: float = 0.98) -> np.ndarray:\n",
        "    return np.clip(x, -limit, limit).astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# speech-shaped noise\n",
        "\n",
        "def speech_shaped_noise(\n",
        "    x: np.ndarray,\n",
        "    sr: int,\n",
        "    seed: int = 0,\n",
        "    smooth_hz: float = 260.0,\n",
        "    hp_hz: float | None = None,\n",
        "    lp_hz: float | None = None,\n",
        "    bp_hz: tuple[float, float] | None = (320.0, 5200.0),\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Generate noise shaped to a smoothed magnitude spectrum of x (FFT-based).\"\"\"\n",
        "    from scipy.signal import butter, filtfilt\n",
        "\n",
        "    rng_local = np.random.default_rng(seed)\n",
        "\n",
        "    x = np.asarray(x, dtype=np.float32)\n",
        "    x = x / (np.max(np.abs(x)) + 1e-8)\n",
        "\n",
        "    n = len(x)\n",
        "\n",
        "    # magnitude spectrum of speech\n",
        "    X = np.fft.rfft(x)\n",
        "    mag = np.abs(X)\n",
        "\n",
        "    # smooth magnitude in frequency domain (moving average, width â‰ˆ smooth_hz)\n",
        "    freqs = np.fft.rfftfreq(n, d=1.0 / sr)\n",
        "    df = float(freqs[1] - freqs[0]) if len(freqs) > 1 else 1.0\n",
        "    win = max(3, int(round(smooth_hz / df)))\n",
        "    if win % 2 == 0:\n",
        "        win += 1\n",
        "    kernel = np.ones(win, dtype=np.float32) / win\n",
        "    mag_s = np.convolve(mag, kernel, mode=\"same\")\n",
        "\n",
        "    # random-phase noise with same (smoothed) magnitude\n",
        "    noise = rng_local.standard_normal(n).astype(np.float32)\n",
        "    N = np.fft.rfft(noise)\n",
        "    phase = np.exp(1j * np.angle(N))\n",
        "    Y = mag_s * phase\n",
        "    y = np.fft.irfft(Y, n=n).astype(np.float32)\n",
        "\n",
        "    # filtering: prefer band-pass to keep it higher + not harsh\n",
        "    if bp_hz is not None:\n",
        "        lo, hi = bp_hz\n",
        "        lo = max(10.0, float(lo))\n",
        "        hi = min(float(hi), sr / 2 - 100.0)\n",
        "        b_bp, a_bp = butter(2, [lo / (sr / 2), hi / (sr / 2)], btype=\"bandpass\")\n",
        "        y = filtfilt(b_bp, a_bp, y).astype(np.float32)\n",
        "    else:\n",
        "        if hp_hz is not None and hp_hz > 0:\n",
        "            b_hp, a_hp = butter(2, float(hp_hz) / (sr / 2), btype=\"highpass\")\n",
        "            y = filtfilt(b_hp, a_hp, y).astype(np.float32)\n",
        "\n",
        "        if lp_hz is not None and 0 < lp_hz < (sr / 2):\n",
        "            b_lp, a_lp = butter(2, float(lp_hz) / (sr / 2), btype=\"lowpass\")\n",
        "            y = filtfilt(b_lp, a_lp, y).astype(np.float32)\n",
        "\n",
        "\n",
        "    y = y / (np.max(np.abs(y)) + 1e-8)\n",
        "    return y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24, 24, 24, 24)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load con/abs lists (read-only) \n",
        "\n",
        "def load_list(path: Path) -> pd.DataFrame:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"Missing list: {path}\")\n",
        "    df = pd.read_csv(path, encoding=\"utf-8-sig\")\n",
        "    for col in [\"stimFile\", \"word\"]:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"{path} must contain column '{col}'\")\n",
        "    return df\n",
        "\n",
        "con1 = load_list(LISTS_DIR / \"con_run1.csv\")\n",
        "abs1 = load_list(LISTS_DIR / \"abs_run1.csv\")\n",
        "con2 = load_list(LISTS_DIR / \"con_run2.csv\")\n",
        "abs2 = load_list(LISTS_DIR / \"abs_run2.csv\")\n",
        "\n",
        "len(con1), len(abs1), len(con2), len(abs2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "WindowsPath('C:/Users/kinga/Documents/Blindbrain/4. Courses/fMRI - design of the experiment and data analysis/cognes-auditory-1back-pilot/experiment/resources/audio/con_run1_001.wav')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# audio paths referenced by stimFile\n",
        "\n",
        "def resolve_audio(stim_file: str) -> Path:\n",
        "    stim_file = str(stim_file).replace(\"\\\\\", \"/\").strip()\n",
        "    return ROOT / \"experiment\" / stim_file\n",
        "\n",
        "def get_audio_paths(df: pd.DataFrame) -> list[Path]:\n",
        "    paths = [resolve_audio(s) for s in df[\"stimFile\"].tolist()]\n",
        "    missing = [p for p in paths if not p.exists()]\n",
        "    if missing:\n",
        "        raise FileNotFoundError(f\"Missing audio files (first 5): {missing[:5]}\")\n",
        "    return paths\n",
        "\n",
        "con1_audio = get_audio_paths(con1)\n",
        "abs1_audio = get_audio_paths(abs1)\n",
        "con2_audio = get_audio_paths(con2)\n",
        "abs2_audio = get_audio_paths(abs2)\n",
        "\n",
        "con1_audio[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(72000, 72000)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# target length per run (match existing stimuli)\n",
        "\n",
        "def max_len_samples(paths: list[Path]) -> int:\n",
        "    mx = 0\n",
        "    for p in paths:\n",
        "        x, sr = read_wav(p)\n",
        "        x, sr = resample_if_needed(x, sr, SR_TARGET)\n",
        "        mx = max(mx, len(x))\n",
        "    return int(mx)\n",
        "\n",
        "target_len_run1 = max_len_samples(con1_audio + abs1_audio)\n",
        "target_len_run2 = max_len_samples(con2_audio + abs2_audio)\n",
        "\n",
        "target_len_run1, target_len_run2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(         word condition  run                           stimFile\n",
              " 0  <BASELINE>      BASE    1  resources/audio/base_run1_001.wav\n",
              " 1  <BASELINE>      BASE    1  resources/audio/base_run1_002.wav\n",
              " 2  <BASELINE>      BASE    1  resources/audio/base_run1_003.wav\n",
              " 3  <BASELINE>      BASE    1  resources/audio/base_run1_004.wav\n",
              " 4  <BASELINE>      BASE    1  resources/audio/base_run1_005.wav,\n",
              "          word condition  run                           stimFile\n",
              " 0  <BASELINE>      BASE    2  resources/audio/base_run2_001.wav\n",
              " 1  <BASELINE>      BASE    2  resources/audio/base_run2_002.wav\n",
              " 2  <BASELINE>      BASE    2  resources/audio/base_run2_003.wav\n",
              " 3  <BASELINE>      BASE    2  resources/audio/base_run2_004.wav\n",
              " 4  <BASELINE>      BASE    2  resources/audio/base_run2_005.wav)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# build baseline per trial\n",
        "\n",
        "def pick_sources(con_paths: list[Path], abs_paths: list[Path], n: int, rng_local: np.random.Generator):\n",
        "    \"\"\"Pick ~50/50 CON/ABS source files without replacement.\"\"\"\n",
        "    n_con = n // 2\n",
        "    n_abs = n - n_con\n",
        "\n",
        "    con_sel = rng_local.choice(con_paths, size=min(n_con, len(con_paths)), replace=False).tolist()\n",
        "    abs_sel = rng_local.choice(abs_paths, size=min(n_abs, len(abs_paths)), replace=False).tolist()\n",
        "\n",
        "    chosen = [(\"CON\", p) for p in con_sel] + [(\"ABS\", p) for p in abs_sel]\n",
        "\n",
        "    if len(chosen) < n:\n",
        "        pool = [(\"CON\", p) for p in con_paths if p not in con_sel] + [(\"ABS\", p) for p in abs_paths if p not in abs_sel]\n",
        "        rng_local.shuffle(pool)\n",
        "        chosen += pool[: (n - len(chosen))]\n",
        "\n",
        "    rng_local.shuffle(chosen)\n",
        "    return chosen[:n]\n",
        "\n",
        "\n",
        "def generate_baseline_for_run(\n",
        "    run: int,\n",
        "    con_paths: list[Path],\n",
        "    abs_paths: list[Path],\n",
        "    target_len: int,\n",
        "    out_list_path: Path,\n",
        "    out_audio_prefix: str,\n",
        "    n_trials: int,\n",
        "    seed: int,\n",
        ") -> pd.DataFrame:\n",
        "    rng_local = np.random.default_rng(seed)\n",
        "    chosen = pick_sources(con_paths, abs_paths, n_trials, rng_local)\n",
        "\n",
        "    rows = []\n",
        "    for i, (src_cond, src_path) in enumerate(chosen, start=1):\n",
        "        x, sr = read_wav(src_path)\n",
        "        x, sr = resample_if_needed(x, sr, SR_TARGET)\n",
        "        x = pad_or_trim(x, target_len)\n",
        "\n",
        "        y = speech_shaped_noise(\n",
        "            x,\n",
        "            sr=sr,\n",
        "            seed=seed + i,\n",
        "            smooth_hz=SSN_SMOOTH_HZ,\n",
        "            bp_hz=SSN_BP_HZ,\n",
        "        )\n",
        "\n",
        "\n",
        "        y = match_rms(y, target_rms=rms(x))\n",
        "        y = y * 0.45\n",
        "        y = pad_or_trim(y, target_len)\n",
        "\n",
        "        y = hard_clip(y, limit=0.98)\n",
        "\n",
        "        out_wav_name = f\"{out_audio_prefix}_{i:03d}.wav\"\n",
        "        out_wav_path = AUDIO_DIR / out_wav_name\n",
        "        write_wav(out_wav_path, y, sr)\n",
        "\n",
        "        rows.append(\n",
        "            {\n",
        "                \"word\": \"<BASELINE>\",\n",
        "                \"condition\": \"BASE\",\n",
        "                \"run\": run,\n",
        "                \"stimFile\": f\"resources/audio/{out_wav_name}\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "    base_df = pd.DataFrame(rows)\n",
        "\n",
        "    # zapis do PsychoPy: tylko 4 kolumny\n",
        "    base_df[[\"word\", \"condition\", \"run\", \"stimFile\"]].to_csv(\n",
        "        out_list_path, index=False, encoding=CSV_ENCODING\n",
        "    )\n",
        "\n",
        "    return base_df\n",
        "\n",
        "\n",
        "\n",
        "n_base1 = int(N_BASE_PER_RUN if N_BASE_PER_RUN is not None else len(con1))\n",
        "n_base2 = int(N_BASE_PER_RUN if N_BASE_PER_RUN is not None else len(con2))\n",
        "\n",
        "base1_df = generate_baseline_for_run(\n",
        "    run=1,\n",
        "    con_paths=con1_audio,\n",
        "    abs_paths=abs1_audio,\n",
        "    target_len=target_len_run1,\n",
        "    out_list_path=LISTS_DIR / \"base_run1.csv\",\n",
        "    out_audio_prefix=\"base_run1\",\n",
        "    n_trials=n_base1,\n",
        "    seed=RNG_SEED,\n",
        ")\n",
        "\n",
        "base2_df = generate_baseline_for_run(\n",
        "    run=2,\n",
        "    con_paths=con2_audio,\n",
        "    abs_paths=abs2_audio,\n",
        "    target_len=target_len_run2,\n",
        "    out_list_path=LISTS_DIR / \"base_run2.csv\",\n",
        "    out_audio_prefix=\"base_run2\",\n",
        "    n_trials=n_base2,\n",
        "    seed=RNG_SEED + 1,\n",
        ")\n",
        "\n",
        "base1_df.head(), base2_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run1 BASE wavs: 24\n",
            "Run2 BASE wavs: 24\n",
            "Saved lists:\n",
            " - C:\\Users\\kinga\\Documents\\Blindbrain\\4. Courses\\fMRI - design of the experiment and data analysis\\cognes-auditory-1back-pilot\\experiment\\resources\\lists\\base_run1.csv\n",
            " - C:\\Users\\kinga\\Documents\\Blindbrain\\4. Courses\\fMRI - design of the experiment and data analysis\\cognes-auditory-1back-pilot\\experiment\\resources\\lists\\base_run2.csv\n",
            "Example baseline: base_run1_001.wav sr= 48000 len_s= 1.5\n",
            "Run1 counterbalance: (source_condition not stored)\n",
            "Run2 counterbalance: (source_condition not stored)\n"
          ]
        }
      ],
      "source": [
        "def list_audio(prefix: str):\n",
        "    return sorted([p.name for p in AUDIO_DIR.glob(prefix)])\n",
        "\n",
        "print(\"Run1 BASE wavs:\", len(list_audio(\"base_run1_*.wav\")))\n",
        "print(\"Run2 BASE wavs:\", len(list_audio(\"base_run2_*.wav\")))\n",
        "print(\"Saved lists:\")\n",
        "print(\" -\", LISTS_DIR / \"base_run1.csv\")\n",
        "print(\" -\", LISTS_DIR / \"base_run2.csv\")\n",
        "\n",
        "p = AUDIO_DIR / list_audio(\"base_run1_*.wav\")[0]\n",
        "x, sr = read_wav(p)\n",
        "print(\"Example baseline:\", p.name, \"sr=\", sr, \"len_s=\", len(x)/sr)\n",
        "\n",
        "for label, df_ in [(\"Run1\", base1_df), (\"Run2\", base2_df)]:\n",
        "    if \"source_condition\" in df_.columns:\n",
        "        print(label, \"counterbalance:\")\n",
        "        print(df_[\"source_condition\"].value_counts())\n",
        "    else:\n",
        "        print(label, \"counterbalance: (source_condition not stored)\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
